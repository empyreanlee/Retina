{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xjbm87nPhdsM"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning\n",
        "import pytorch_lightning as pl\n",
        "pl.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZAd-Y2D9arf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_fhXSQYShssx"
      },
      "outputs": [],
      "source": [
        "weights_url = \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\"\n",
        "!wget -nc {weights_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3ryTqgJGHtQ"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "Labels = ['herd', 'not_herd']\n",
        "batch_size = 32\n",
        "efficientnet_weights_path = \"efficientnet_b0_rwightman-7f5810bc.pth\"\n",
        "scheduler_step = 7\n",
        "gamma = 0.1\n",
        "IMAGE_MODE = 'RGB'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toBxQ_LiGg_K"
      },
      "source": [
        "EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hS0rO2ChieZ"
      },
      "outputs": [],
      "source": [
        "class EfficientnetB0(nn.Module):\n",
        "    def __init__(self, list_of_classes, weights_path=None):\n",
        "        super(EfficientnetB0, self).__init__()\n",
        "        self.list_of_classes = list_of_classes\n",
        "        self.num_classes = len(self.list_of_classes)\n",
        "        self.model = self.load_efficientnet(weights_path)\n",
        "        self.model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2, inplace=True),\n",
        "            nn.Linear(in_features=1280, out_features=self.num_classes, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def load_efficientnet(self, weights_path):\n",
        "        model = models.efficientnet_b0(weights=None)\n",
        "        if weights_path:\n",
        "            print('Loading Weights')\n",
        "            state_dict = torch.load(weights_path, weights_only=True)\n",
        "            model.load_state_dict(state_dict)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoYsgxWGdwq"
      },
      "source": [
        "Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "est5D1eCGfs3"
      },
      "outputs": [],
      "source": [
        "class Classifier(pl.LightningModule):\n",
        "  def __init__(self, list_of_labels, learning_rate=1e-4, weight_decay=1e-4, scheduler_step_size=20, scheduler_gamma=0.1):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.list_of_labels = list_of_labels\n",
        "    self.num_classes = len(list_of_labels)\n",
        "    self.model = EfficientnetB0(self.list_of_labels, efficientnet_weights_path)\n",
        "    # self.model.classifier = nn.Sequential(\n",
        "    #     nn.Dropout(0.2, inplace=True),\n",
        "    #     nn.Linear(in_features=1280, out_features=self.num_classes, bias=True),\n",
        "    #     nn.Sigmoid\n",
        "    # )\n",
        "    self.loss_fn = nn.BCELoss()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weight_decay = weight_decay\n",
        "    self.scheduler_step_size = scheduler_step_size\n",
        "    self.scheduler_gamma = scheduler_gamma\n",
        "    self.train_outputs = []\n",
        "    self.valid_outputs = []\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    image, label = batch\n",
        "    image = image.float()\n",
        "    label = label.to(torch.float)\n",
        "    pred = self(image)\n",
        "    loss = self.loss_fn(pred, label)\n",
        "\n",
        "    self.log('train_loss', loss, prog_bar=True)\n",
        "    self.train_outputs.append((label.cpu().numpy(), pred.cpu().detach().numpy()))\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    image, label = batch\n",
        "    image = image.float()\n",
        "    label = label.to(torch.float)\n",
        "    pred = self(image)\n",
        "    loss = self.loss_fn(pred, label)\n",
        "\n",
        "    self.log('val_loss', loss, prog_bar=True)\n",
        "    self.valid_outputs.append((label.cpu().numpy(), pred.cpu().detach().numpy()))\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=self.scheduler_step_size, gamma=self.scheduler_gamma)\n",
        "    return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeG1NbMKMBxv"
      },
      "outputs": [],
      "source": [
        "class Counter(Dataset):\n",
        "  def __init__(self, list_of_classes, is_training, image_paths, image_labels):\n",
        "    self.list_of_classes = list_of_classes\n",
        "    self.num_classes = len(self.list_of_classes)\n",
        "    self.class_to_index = {class_name: idx for idx, class_name in enumerate(list_of_classes)}\n",
        "    self.image_paths = image_paths\n",
        "    self.is_training = is_training\n",
        "    self.image_labels = image_labels\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ])\n",
        "\n",
        "    if self.is_training:\n",
        "      transform = transforms.Compose([\n",
        "          transform,\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "      ])\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = Image.open(self.image_paths[idx])\n",
        "    if image.mode != IMAGE_MODE:\n",
        "      image = image.convert(IMAGE_MODE)\n",
        "    image = self.transform(image)\n",
        "\n",
        "    label = self.image_labels[idx]\n",
        "    label = torch.nn.functional.one_hot(torch.tensor(label), num_classes=self.num_classes)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  @staticmethod\n",
        "  def collate_fn(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    images = torch.stack(images, dim=0)\n",
        "    labels = torch.stack(labels, dim=0)\n",
        "    return images, labels\n",
        "\n",
        "class DataModule(pl.LightningDataModule):\n",
        "  def __init__(self, list_of_classes, train_labels, val_labels, train_image_paths, val_image_paths, batch_size=batch_size):\n",
        "    super().__init__()\n",
        "    self.list_of_classes = list_of_classes\n",
        "    self.train_labels = train_labels\n",
        "    self.val_labels = val_labels\n",
        "    self.train_image_paths = train_image_paths\n",
        "    self.val_image_paths = val_image_paths\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def prepare_data(self):\n",
        "    pass\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    if stage == 'fit' or stage==None:\n",
        "      self.train_dataset = Counter(\n",
        "          list_of_classes=self.list_of_classes,\n",
        "          is_training=True,\n",
        "          image_paths=self.train_image_paths,\n",
        "          image_labels=self.train_labels\n",
        "          )\n",
        "      self.val_dataset = Counter(\n",
        "          list_of_classes=self.list_of_classes,\n",
        "          is_training=False,\n",
        "          image_paths=self.val_image_paths,\n",
        "          image_labels=self.val_labels\n",
        "      )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_dataset,\n",
        "                      batch_size=self.batch_size,\n",
        "                      shuffle=True,\n",
        "                      pin_memory=True,\n",
        "                      num_workers=os.cpu_count(),\n",
        "                      drop_last=True,\n",
        "                      collate_fn=self.train_dataset.collate_fn\n",
        "                      )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_dataset,\n",
        "                      batch_size=self.batch_size,\n",
        "                      shuffle=False,\n",
        "                      pin_memory=True,\n",
        "                      num_workers=os.cpu_count(),\n",
        "                      drop_last=True,\n",
        "                      collate_fn=self.val_dataset.collate_fn\n",
        "                      )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0TyJ4WQfOWE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF6I1pOBf6nV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "df = pd.read_csv('Herd_Data.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gewJdLcii5oD"
      },
      "outputs": [],
      "source": [
        "label_names = df['class'].unique().tolist()\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "48iQZEQajJRl"
      },
      "outputs": [],
      "source": [
        "df[\"category\"] = (df['class'] == 'herd').astype(int)\n",
        "df['filepath'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hbUtLB3jmUa1"
      },
      "outputs": [],
      "source": [
        "part = r'^...-\\d+/images/...\\d{4}\\.JPG$'\n",
        "df[df['filepath'].apply(lambda x: not re.match(part, x))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crsPVWuBwPUZ"
      },
      "outputs": [],
      "source": [
        "df['filepath'] = df['filepath'].str.strip('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcKsmAEPxXLZ"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('Herd.csv')\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZPADSn6nFmv"
      },
      "outputs": [],
      "source": [
        "image_paths = df['filepath'].tolist()\n",
        "image_paths = [os.path.join('...', path) for path in image_paths]\n",
        "labels = df['category'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GRv_pbUvbYZB"
      },
      "outputs": [],
      "source": [
        "image_paths[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "17d0loybmIPD"
      },
      "outputs": [],
      "source": [
        "image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiPX1vTPiQOK"
      },
      "outputs": [],
      "source": [
        "if os.path.exists(b_path):\n",
        "  print('exists')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pRbDd46rcT2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "train_image_paths = []\n",
        "train_labels = []\n",
        "val_image_paths = []\n",
        "val_labels = []\n",
        "\n",
        "for i in range(len(image_paths)):\n",
        "  match = re.search(r'MC005-Batch-(\\d+)', image_paths[i])\n",
        "  if match:\n",
        "    batch_number = int(match.group(1))\n",
        "    if 1 <= batch_number <= 28:\n",
        "      train_image_paths.append(image_paths[i])\n",
        "      train_labels.append(labels[i])\n",
        "    elif 29<= batch_number <= 32:\n",
        "      val_image_paths.append(image_paths[i])\n",
        "      val_labels.append(labels[i])\n",
        "\n",
        "print(f\"Train: {len(train_image_paths)} Val: {len(val_image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pz709vbjQlqg"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFshB5jgQqlA"
      },
      "outputs": [],
      "source": [
        "# prompt: Using dataframe df: change category to have 0 for herd and 1 for non-herd\n",
        "\n",
        "# Create a mapping for the class categories to numerical values\n",
        "class_mapping = {'herd': 0, 'non-herd': 1}\n",
        "\n",
        "# Use the mapping to update the 'category' column\n",
        "df['category'] = df['class'].map(class_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZM2xJwHrGafA"
      },
      "outputs": [],
      "source": [
        "#data module\n",
        "data_module = DataModule(label_names, train_labels, val_labels,\n",
        "                              train_image_paths,val_image_paths, batch_size)\n",
        "\n",
        "#model init\n",
        "model = Classifier(label_names)\n",
        "\n",
        "#checkpointing\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor= 'val_loss',\n",
        "    dirpath='./checkpoints',\n",
        "    save_top_k=1,\n",
        "    mode='min',\n",
        "    filename='classifier-{epoch:02d}-{val_loss:.2f}',\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs = epochs,\n",
        "    default_root_dir='model',\n",
        "    #callbacks = [checkpoint_callback],\n",
        "    #accelerator='auto',\n",
        "    #strategy='ddp',\n",
        "\n",
        ")\n",
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_gouvatcOOG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9rEzD4AYNIU"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "batch_paths = glob.glob(\"/content/...*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdztQM8DXB2V"
      },
      "outputs": [],
      "source": [
        "batches = os.listdir('/content/...')\n",
        "\n",
        "\n",
        "\n",
        "for batch_path in tqdm(batch_paths):\n",
        "    batch = os.path.basename(batch_path)\n",
        "    batch_images = os.listdir(os.path.join(batch_path, 'images'))\n",
        "    batch_image_paths = [os.path.join(batch_path, 'images', i) for i in batch_images]\n",
        "\n",
        "    dataset = fo.Dataset(batch, overwrite=True)\n",
        "\n",
        "    # Add the images to the dataset\n",
        "    for img_path in batch_image_paths:\n",
        "        try:\n",
        "            sample = fo.Sample(filepath=img_path)\n",
        "            dataset.add_sample(sample)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLTL4ix9YTGP"
      },
      "outputs": [],
      "source": [
        "session = fo.launch_app(dataset, auto=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC422CunYT9h"
      },
      "outputs": [],
      "source": [
        "session.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkHh9fxWrH3s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkdHrSTgSY5nUOhOHxLsPR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}